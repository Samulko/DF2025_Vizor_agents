"""
Bridge Design Chat Agent using Gemini Live API.

Handles real-time voice conversation and delegates complex bridge design tasks
to the BridgeDesignSupervisor via tools. Follows OpenAI realtime agents pattern.
"""

import asyncio
import base64
import json
import os
import pathlib
import time
import uuid
from typing import AsyncGenerator, Literal, Dict, Any, List
import numpy as np
from dotenv import load_dotenv

try:
    from fastrtc import AsyncStreamHandler, Stream, wait_for_item
    from google import genai
    from google.genai.types import LiveConnectConfig, PrebuiltVoiceConfig, SpeechConfig, VoiceConfig
    CHAT_DEPENDENCIES_AVAILABLE = True
except ImportError:
    CHAT_DEPENDENCIES_AVAILABLE = False

from ..config.logging_config import get_logger
from ..ipc import send_bridge_design_request

logger = get_logger(__name__)
load_dotenv()


def encode_audio(data: np.ndarray) -> str:
    """Encode Audio data to send to the server"""
    return base64.b64encode(data.tobytes()).decode("UTF-8")


class BridgeChatHandler(AsyncStreamHandler):
    """
    Chat handler for bridge design using Gemini Live API with bridge design supervisor tools.
    
    This handles:
    - Real-time voice conversation 
    - Simple bridge engineering questions
    - Tool calls to bridge design supervisor for complex tasks
    """

    def __init__(self, expected_layout: Literal["mono"] = "mono", output_sample_rate: int = 24000):
        super().__init__(expected_layout, output_sample_rate, input_sample_rate=16000)
        
        # Async queues for audio
        self.input_queue: asyncio.Queue = asyncio.Queue()
        self.output_queue: asyncio.Queue = asyncio.Queue()
        self.quit: asyncio.Event = asyncio.Event()
        
        # Initialize session as None - will be set in start_up
        self.session = None
        
        # Two-terminal architecture: shared state for IPC communication
        self.processing_tasks: Dict[str, Dict] = {}  # Track active processing tasks
        self.task_lock = asyncio.Lock()  # Thread-safe access to shared state
        
        logger.info("ğŸŒ‰ Bridge chat handler initialized for two-terminal IPC architecture")
        
        # Add startup diagnostic info
        self.startup_diagnostics = {
            "handler_initialized": True,
            "session_created": False,
            "microphone_test_passed": False,
            "gemini_connected": False
        }

    def copy(self) -> "BridgeChatHandler":
        return BridgeChatHandler(expected_layout="mono", output_sample_rate=self.output_sample_rate)

    async def start_up(self):
        """Initialize Gemini Live session with bridge design tools."""
        print("ğŸ”§ [DEBUG] Starting Gemini Live session initialization...")
        
        # Enhanced startup with better error handling
        try:
            await self._check_microphone_availability()
        except Exception as e:
            print(f"âš ï¸ [WARNING] Microphone check failed: {e}")
            print("   This might indicate browser permission issues")
            print("   The system will still try to start - grant permissions when prompted")
        
        # Get API key from environment directly (no user input required)
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables. Please set it in your .env file.")
        
        print("âœ… [DEBUG] API key found, creating Gemini client...")
        
        # Get voice selection from UI if available, otherwise default
        if not self.phone_mode:
            print("ğŸ¤ [DEBUG] Waiting for voice selection from UI...")
            await self.wait_for_args()
            voice_name = self.latest_args[1] if len(self.latest_args) > 1 else "Puck"
        else:
            voice_name = "Puck"  # Default voice for phone mode
        
        print(f"ğŸ—£ï¸  [DEBUG] Selected voice: {voice_name}")
        
        client = genai.Client(
            api_key=api_key,
            http_options={"api_version": "v1alpha"},
        )

        # Create tools and get debug info
        tools = self._create_gemini_tools()
        print(f"ğŸ› ï¸  [DEBUG] Created {len(tools)} Gemini tools for function calling")
        for i, tool in enumerate(tools):
            # Handle new dictionary format for Live API tools
            if isinstance(tool, dict) and 'function_declarations' in tool:
                for func_decl in tool['function_declarations']:
                    print(f"    Tool {i+1}: {func_decl['name']} - {func_decl['description'][:50]}...")
                    print(f"    Tool {i+1} Parameters: {list(func_decl['parameters']['properties'].keys())}")
            else:
                # Fallback for old format (shouldn't happen now)
                print(f"    Tool {i+1}: {tool} - Unknown format")

        # Use Gemini API-compliant tool declaration
        config = {
            "response_modalities": ["AUDIO"],
            "speech_config": {
                "voice_config": {
                    "prebuilt_voice_config": {"voice_name": voice_name}
                }
            },
            "tools": tools,
            "system_instruction": self._get_bridge_chat_prompt(),
        }
        
        print("ğŸš€ [DEBUG] Connecting to Gemini Live API...")

        print(f"ğŸ”§ [DEBUG] Config being sent to Gemini Live API:")
        print(f"    Response Modalities: {config['response_modalities']}")
        print(f"    Voice Name: {config['speech_config']['voice_config']['prebuilt_voice_config']['voice_name']}")
        print(f"    Tools: {[tool['function_declarations'][0]['name'] for tool in config['tools']]}")
        print(f"    System Instruction Length: {len(config['system_instruction'])} chars")
        
        async with client.aio.live.connect(model="gemini-live-2.5-flash-preview", config=config) as session:
            print("âœ… [DEBUG] Connected to Gemini Live API successfully!")
            print(f"ğŸ”— [DEBUG] Session object: {type(session)}")
            print(f"ğŸ”§ [DEBUG] Session available methods: {[attr for attr in dir(session) if not attr.startswith('_')]}")
            print("ğŸ§ [DEBUG] Audio streaming active - you can now speak to the system")
            print("ğŸ”„ [DEBUG] Waiting for user input...")
            
            # Update diagnostics
            self.startup_diagnostics["session_created"] = True
            self.startup_diagnostics["gemini_connected"] = True
            
            # Handle tool calls with enhanced debugging
            print("ğŸ› ï¸  [DEBUG] Using manual tool call detection (Live API requires manual handling)")
            
            # Check if session has tool-related attributes
            tool_attrs = [attr for attr in dir(session) if 'tool' in attr.lower()]
            if tool_attrs:
                print(f"ğŸ” [DEBUG] Session tool-related attributes: {tool_attrs}")
            
            # Store session for manual tool handling
            self.session = session
            
            print("ğŸ› ï¸  [DEBUG] Starting audio stream with manual tool detection...")
            
            # CRITICAL: Live API terminates start_stream after tool calls
            # Solution: Restart stream within same session after each tool call
            print("ğŸ”„ [SESSION] Starting perpetual audio stream with restart capability...")
            
            while not self.quit.is_set():
                try:
                    print("ğŸ¤ [SESSION] Starting/Restarting audio stream...")
                    stream_iteration = 0
                    
                    async for audio in session.start_stream(stream=self.stream(), mime_type="audio/pcm"):
                        stream_iteration += 1
                        print(f"ğŸ“¨ [DEBUG] Stream iteration {stream_iteration}: Received {type(audio)}")
                        
                        # Enhanced response debugging
                        if hasattr(audio, '__dict__'):
                            print(f"ğŸ“¨ [DEBUG] Audio response attributes: {list(audio.__dict__.keys())}")
                        
                        # Handle audio data
                        if audio.data:
                            print(f"ğŸ”Š [DEBUG] Audio data received: {len(audio.data)} bytes")
                            array = np.frombuffer(audio.data, dtype=np.int16)
                            self.output_queue.put_nowait((self.output_sample_rate, array))
                        
                        # Check for tool calls in the audio response
                        tool_called = False
                        if hasattr(audio, 'tool_call') and audio.tool_call:
                            print("\n" + "ğŸ†"*60)
                            print("ğŸ† [BREAKTHROUGH] VOICE TOOL CALL IN AUDIO! ğŸ†")
                            print("ğŸ†"*60)
                            await self._handle_tool_call(audio.tool_call)
                            tool_called = True
                        
                        # Check for server content with tool calls
                        if hasattr(audio, 'server_content') and audio.server_content:
                            if hasattr(audio.server_content, 'tool_call') and audio.server_content.tool_call:
                                print("\n" + "ğŸ†"*60)
                                print("ğŸ† [BREAKTHROUGH] VOICE TOOL CALL IN SERVER CONTENT! ğŸ†")
                                print("ğŸ†"*60)
                                await self._handle_tool_call(audio.server_content.tool_call)
                                tool_called = True
                        
                        # If tool was called, the stream will likely end soon
                        if tool_called:
                            print("âš ï¸ [SESSION] Tool called - stream will likely terminate, preparing to restart...")
                    
                    # Stream ended (normal after tool calls)
                    print("ğŸ”„ [SESSION] Stream ended (expected after tool call), restarting in 0.5s...")
                    await asyncio.sleep(0.5)  # Brief pause before restart
                    
                except asyncio.CancelledError:
                    print("ğŸ›‘ [SESSION] Stream cancelled, exiting...")
                    break
                except Exception as e:
                    print(f"ğŸ’¥ [SESSION ERROR] Stream exception: {e}")
                    logger.error(f"Stream error: {e}")
                    import traceback
                    traceback.print_exc()
                    print("ğŸ”„ [SESSION] Attempting to restart after error...")
                    await asyncio.sleep(1.0)  # Longer pause after error
            
            print("ğŸ [SESSION] Exited perpetual stream loop")
    

    def _create_gemini_tools(self):
        """Create tool declarations for Gemini Live API (function_declarations format)."""
        
        # Define the function declarations for Live API - Two-terminal architecture
        bridge_design_request_declaration = {
            "name": "bridge_design_request",
            "description": "Send bridge design request to main.py system via TCP IPC. This implements two-terminal architecture: voice terminal communicates with main bridge design terminal.",
            "parameters": {
                "type": "object",
                "properties": {
                    "user_request": {
                        "type": "string",
                        "description": "The user's request about bridge design, engineering, or system operations"
                    }
                },
                "required": ["user_request"]
            }
        }
        
        # Status checking tool for two-terminal architecture
        are_smolagents_finished_declaration = {
            "name": "are_smolagents_finished_yet",
            "description": "Check if the main.py system has finished processing bridge design tasks. Returns status and results if available.",
            "parameters": {
                "type": "object",
                "properties": {
                    "task_id": {
                        "type": "string", 
                        "description": "Optional task ID to check specific task. If not provided, checks all active tasks."
                    }
                },
                "required": []
            }
        }
        
        # Diagnostic tool for troubleshooting
        diagnostics_declaration = {
            "name": "get_system_diagnostics",
            "description": "Get system diagnostics for troubleshooting voice interface issues. Use when user reports connection problems.",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
        
        # Return in Live API format - all tools
        tools = [{"function_declarations": [bridge_design_request_declaration, are_smolagents_finished_declaration, diagnostics_declaration]}]
        logger.info(f"âœ… Created {len(tools[0]['function_declarations'])} tool declarations for Live API")
        return tools
    
    def _execute_bridge_design_request(self, user_request: str) -> str:
        """Execute bridge design request - Send via IPC to main.py system, returns immediately."""
        print("\n" + "ğŸ†"*50)
        print("ğŸ† [TWO-TERMINAL] VOICE TERMINAL SENDING TO MAIN TERMINAL! ğŸ†")
        print("ğŸ†"*50)
        
        # Check if there are any active processing tasks
        active_tasks = [tid for tid, task in self.processing_tasks.items() 
                       if task["status"] in ["started", "processing"]]
        
        if active_tasks:
            active_task_info = []
            for tid in active_tasks:
                task = self.processing_tasks[tid]
                elapsed = time.time() - task["started_at"]
                active_task_info.append(f"Task {tid}: '{task['user_request'][:30]}...' ({elapsed:.1f}s)")
            
            print(f"âš ï¸ [VOICE TERMINAL] Blocking new request - {len(active_tasks)} active tasks")
            for info in active_task_info:
                print(f"   ğŸ“‹ {info}")
            
            return f"âš ï¸ Please wait! I'm still processing {len(active_tasks)} task{'s' if len(active_tasks) > 1 else ''}:\n" + \
                   "\n".join([f"â€¢ {info}" for info in active_task_info]) + \
                   f"\n\nAsk me 'are the smolagents finished yet?' to check status, then try your request again when completed."
        
        # Generate unique task ID for tracking
        task_id = str(uuid.uuid4())[:8]
        timestamp = time.time()
        
        print(f"ğŸš¨ [VOICE TERMINAL] Starting bridge_design_request()")
        print(f"ğŸ“ [USER REQUEST] {user_request}")
        print(f"ğŸ·ï¸ [TASK ID] {task_id}")
        print(f"ğŸ•° [TIMESTAMP] {timestamp}")
        
        try:
            # Initialize task state in shared memory (thread-safe)
            task_state = {
                "task_id": task_id,
                "user_request": user_request,
                "status": "started",
                "started_at": timestamp,
                "finished_at": None,
                "result": None,
                "error": None
            }
            
            # Thread-safe: Add to shared state
            self.processing_tasks[task_id] = task_state
            
            print(f"ğŸ§µ [VOICE TERMINAL] Task {task_id} added to shared state")
            print("ğŸ¯ [VOICE TERMINAL] Starting IPC processing thread...")
            
            # Start processing in separate thread (async task)
            asyncio.create_task(self._run_ipc_processing_thread(task_id))
            
            return f"ğŸš€ Started processing your request (Task ID: {task_id}). The main bridge design system is working on it. You can ask me 'are the smolagents finished yet?' to check status, or continue our conversation!"
                
        except Exception as e:
            print(f"ğŸ’¥ [VOICE TERMINAL ERROR] Exception in bridge_design_request: {e}")
            import traceback
            traceback.print_exc()
            return f"âŒ Error starting processing: {str(e)}"
    
    def _execute_are_smolagents_finished_yet(self, task_id: str = None) -> str:
        """Check if main.py processing has finished - Voice terminal polls status."""
        print(f"ğŸ” [VOICE TERMINAL] Checking main.py status for task_id: {task_id}")
        
        try:
            if not self.processing_tasks:
                return "ğŸ¤· No active processing tasks found. Start a task first with bridge_design_request."
            
            if task_id:
                # Check specific task
                if task_id not in self.processing_tasks:
                    return f"âŒ Task ID {task_id} not found. Active tasks: {list(self.processing_tasks.keys())}"
                    
                task = self.processing_tasks[task_id]
                status = task["status"]
                
                if status == "completed":
                    result = task["result"]
                    elapsed = task["finished_at"] - task["started_at"] 
                    # Clean up completed task
                    del self.processing_tasks[task_id]
                    return f"âœ… Task {task_id} completed! ({elapsed:.1f}s)\n\nResult: {result}"
                elif status == "error":
                    error = task["error"]
                    # Clean up failed task
                    del self.processing_tasks[task_id]
                    return f"âŒ Task {task_id} failed: {error}"
                else:
                    elapsed = time.time() - task["started_at"]
                    return f"ğŸ”„ Task {task_id} still processing... ({elapsed:.1f}s elapsed). Request: '{task['user_request'][:50]}...'"
            
            else:
                # Check all tasks
                results = []
                for tid, task in list(self.processing_tasks.items()):
                    if task["status"] == "completed":
                        result = task["result"]
                        elapsed = task["finished_at"] - task["started_at"]
                        results.append(f"âœ… Task {tid} completed ({elapsed:.1f}s): {result}")
                        del self.processing_tasks[tid]
                    elif task["status"] == "error":
                        error = task["error"] 
                        results.append(f"âŒ Task {tid} failed: {error}")
                        del self.processing_tasks[tid]
                    else:
                        elapsed = time.time() - task["started_at"]
                        results.append(f"ğŸ”„ Task {tid} processing ({elapsed:.1f}s): '{task['user_request'][:30]}...'")
                
                if not results:
                    return "ğŸ¤· No active tasks found."
                    
                return "\n".join(results)
                
        except Exception as e:
            print(f"ğŸ’¥ [VOICE TERMINAL ERROR] Exception checking status: {e}")
            return f"âŒ Error checking status: {str(e)}"

    async def _run_ipc_processing_thread(self, task_id: str):
        """Execute bridge design request via IPC to main.py - updates shared state when done."""
        try:
            print(f"ğŸ§µ [IPC THREAD] Starting IPC processing for task {task_id}")
            
            # Get task from shared state
            task = self.processing_tasks.get(task_id)
            if not task:
                print(f"ğŸ’¥ [IPC THREAD] Task {task_id} not found in shared state!")
                return
                
            user_request = task["user_request"]
            print(f"ğŸ¯ [IPC THREAD] Processing: {user_request[:50]}...")
            
            # Update status to processing
            async with self.task_lock:
                self.processing_tasks[task_id]["status"] = "processing"
            
            # Send request via IPC to main.py (this is the heavy, blocking operation)
            print("ğŸ”§ [IPC THREAD] Sending request to main.py via TCP...")
            logger.info(f"ğŸ¯ IPC thread processing: {user_request[:100]}...")
            
            response = await send_bridge_design_request(user_request)
            
            print(f"ğŸ“Š [IPC THREAD] Processing completed for task {task_id}:")
            print(f"    Success: {response.success}")
            print(f"    Message length: {len(response.message) if response.message else 0} characters")
            
            # Update shared state with results (thread-safe)
            async with self.task_lock:
                if response.success:
                    self.processing_tasks[task_id]["status"] = "completed"
                    self.processing_tasks[task_id]["result"] = response.message
                    self.processing_tasks[task_id]["announced"] = False  # Track if result was announced
                    print(f"âœ… [IPC THREAD] Task {task_id} completed successfully")
                    print(f"ğŸ“¤ [IPC RESULT] {response.message}")
                    logger.info(f"âœ… IPC task {task_id} completed: {response.message}")
                else:
                    self.processing_tasks[task_id]["status"] = "error"
                    self.processing_tasks[task_id]["error"] = response.message
                    print(f"âŒ [IPC THREAD] Task {task_id} failed: {response.message}")
                    logger.error(f"âŒ IPC task {task_id} failed: {response.message}")
                
                self.processing_tasks[task_id]["finished_at"] = time.time()
                
        except Exception as e:
            print(f"ğŸ’¥ [IPC THREAD] Exception in task {task_id}: {e}")
            logger.error(f"IPC thread error for task {task_id}: {e}")
            
            # Update shared state with error (thread-safe)
            async with self.task_lock:
                if task_id in self.processing_tasks:
                    self.processing_tasks[task_id]["status"] = "error"
                    self.processing_tasks[task_id]["error"] = str(e)
                    self.processing_tasks[task_id]["finished_at"] = time.time()
            
            import traceback
            traceback.print_exc()

    async def _handle_tool_call(self, tool_call):
        """Handle tool calls from Gemini Live session."""
        try:
            print("\n" + "ğŸ†"*50)
            print("ğŸ† [BREAKTHROUGH] GEMINI TOOL CALL HANDLER TRIGGERED! ğŸ†")
            print("ğŸ†"*50)
            print("\n" + "ğŸ”¥"*50)
            print("ğŸ”¥ [TOOL CALL HANDLER] Gemini Live called _handle_tool_call()")
            print(f"ğŸ”¥ [TOOL CALL TYPE] {type(tool_call)}")
            print(f"ğŸ”¥ [TOOL CALL DETAILS] {tool_call}")
            print(f"ğŸ”¥ [TOOL CALL ATTRS] {dir(tool_call) if hasattr(tool_call, '__dict__') else 'No attributes'}")
            if hasattr(tool_call, '__dict__'):
                print(f"ğŸ”¥ [TOOL CALL DICT] {tool_call.__dict__}")
            print("ğŸ”¥"*50)
            
            logger.info(f"ğŸ› ï¸ Handling Gemini function call: {tool_call}")
            
            # Handle manual function calls - Live API requires manual handling
            if hasattr(tool_call, 'function_calls'):
                function_responses = []
                
                for fc in tool_call.function_calls:
                    print(f"ğŸ“ [FUNCTION CALL] Name: {fc.name}")
                    print(f"ğŸ“ [FUNCTION CALL] ID: {fc.id}")
                    print(f"ğŸ“ [FUNCTION CALL] Args: {fc.args}")
                    
                    # Execute the actual function based on name - Two-thread architecture
                    if fc.name == "bridge_design_request":
                        # Extract arguments
                        user_request = fc.args.get("user_request", "")
                        
                        print(f"ğŸ¯ [EXECUTING] bridge_design_request with args: {fc.args}")
                        
                        # Call the actual function (STS thread)
                        result = self._execute_bridge_design_request(user_request)
                        
                        # Create function response for Live API
                        from google.genai import types
                        function_response = types.FunctionResponse(
                            id=fc.id,
                            name=fc.name,
                            response={"result": result}
                        )
                        function_responses.append(function_response)
                        
                        print(f"âœ… [FUNCTION RESPONSE] Created response for {fc.name}")
                    
                    elif fc.name == "are_smolagents_finished_yet":
                        # Extract arguments for status check
                        task_id = fc.args.get("task_id", None)
                        
                        print(f"ğŸ” [EXECUTING] are_smolagents_finished_yet with args: {fc.args}")
                        
                        # Call the status check function (STS thread)
                        result = self._execute_are_smolagents_finished_yet(task_id)
                        
                        # Create function response for Live API
                        from google.genai import types
                        function_response = types.FunctionResponse(
                            id=fc.id,
                            name=fc.name,
                            response={"result": result}
                        )
                        function_responses.append(function_response)
                        
                        print(f"âœ… [FUNCTION RESPONSE] Created status response for {fc.name}")
                    
                    elif fc.name == "get_system_diagnostics":
                        print(f"ğŸ” [EXECUTING] get_system_diagnostics")
                        
                        # Get diagnostic information
                        diagnostics = self.get_diagnostics()
                        
                        # Format diagnostics for user
                        diag_text = f"""System Diagnostics:
âœ… Handler initialized: {diagnostics['startup_diagnostics'].get('handler_initialized', False)}
âœ… Session created: {diagnostics['startup_diagnostics'].get('session_created', False)}
âœ… Gemini connected: {diagnostics['startup_diagnostics'].get('gemini_connected', False)}
âœ… Microphone test: {diagnostics['startup_diagnostics'].get('microphone_test_passed', False)}
âœ… Active tasks: {diagnostics['active_tasks']}
âœ… Session active: {diagnostics['session_active']}

ğŸ’¡ If microphone isn't working:
1. Check browser permissions (click microphone icon in address bar)
2. Clear browser data and refresh page
3. Try different browser
4. Use text interface fallback"""
                        
                        # Create function response for Live API
                        from google.genai import types
                        function_response = types.FunctionResponse(
                            id=fc.id,
                            name=fc.name,
                            response={"result": diag_text}
                        )
                        function_responses.append(function_response)
                        
                        print(f"âœ… [FUNCTION RESPONSE] Created diagnostics response for {fc.name}")
                    
                    else:
                        print(f"âŒ [UNKNOWN FUNCTION] {fc.name}")
                        # Create error response with helpful suggestion
                        from google.genai import types
                        function_response = types.FunctionResponse(
                            id=fc.id,
                            name=fc.name,
                            response={"error": f"Unknown function: {fc.name}. Available functions: bridge_design_request, are_smolagents_finished_yet, get_system_diagnostics"}
                        )
                        function_responses.append(function_response)
                
                # Send tool responses back to Gemini Live API
                if function_responses:
                    print(f"ğŸ“¤ [SENDING RESPONSES] {len(function_responses)} responses to Gemini")
                    await self.session.send_tool_response(function_responses=function_responses)
                    print("âœ… [RESPONSES SENT] Tool responses sent to Gemini Live API")
                
                return {"status": "Function calls handled successfully"}
            else:
                print("âŒ [ERROR] No function_calls attribute found in tool_call")
                return {"error": "No function_calls found in tool_call"}
                
        except Exception as e:
            print(f"ğŸ’¥ [ERROR] Tool call handler failed: {e}")
            logger.error(f"âŒ Tool call handler error: {e}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}

    def _get_bridge_chat_prompt(self) -> str:
        """Get system prompt for bridge design chat agent from markdown file."""
        prompt_path = pathlib.Path(__file__).parent.parent.parent / ".." / ".." / "system_prompts" / "chat_agent.md"
        prompt_path = prompt_path.resolve()
        try:
            with open(prompt_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            logger.warning(f"Could not load system prompt from {prompt_path}: {e}. Using fallback.")
            return """You are a helpful bridge design assistant that can have natural conversations about bridge engineering.

You operate in a two-terminal architecture where you send requests to the main bridge design system via TCP IPC.

**CRITICAL TASK MANAGEMENT RULE:**
BEFORE sending ANY new bridge_design_request, you MUST FIRST check if previous tasks are finished by calling the are_smolagents_finished_yet tool. Only send new requests when all previous tasks are completed or failed.

**WORKFLOW:**
1. For bridge design tasks: First call are_smolagents_finished_yet
2. If tasks are still processing: Tell user to wait and explain what's being processed
3. If tasks are finished: Then proceed with bridge_design_request
4. For simple questions: Respond directly without tools

**For simple questions**, you can respond directly:
- Basic bridge engineering concepts
- Material properties and standards
- General design principles
- Terminology explanations

**For ANY bridge design tasks**, you MUST follow the workflow above:
- Creating or modifying bridge components
- Structural analysis and calculations  
- Parametric design in Grasshopper
- Multi-step engineering workflows
- Component coordination
- System status checks
- Any request related to bridge design

Available tools:
- `are_smolagents_finished_yet`: Check if main.py has finished processing tasks - CALL THIS FIRST
- `bridge_design_request`: Sends requests to main.py bridge design system via TCP IPC - ONLY AFTER CHECKING STATUS
- `get_system_diagnostics`: Get diagnostic information when user reports technical issues

Examples of proper workflow:
- User: "Create a simple beam bridge"
- Assistant: [calls are_smolagents_finished_yet first]
- If busy: "I'm still processing a previous task. Please wait..."
- If free: [calls bridge_design_request with the user's request]

**TROUBLESHOOTING SUPPORT:**
If user reports microphone/connection issues:
1. Use get_system_diagnostics to check system status
2. Guide them through common fixes:
   - Browser permissions (click microphone icon in address bar)
   - Clear browser data and refresh page
   - Try different browser
   - Use text interface fallback

Two-Terminal Architecture:
- Terminal 1: main.py (bridge design system with --enable-command-server)
- Terminal 2: voice chat (this interface) communicates via TCP

Keep responses concise and natural for voice interaction. Be technical but accessible. When using tools, explain what you're doing and interpret the results for the user.

REMEMBER: ALWAYS check task status BEFORE sending new bridge design requests. This prevents overwhelming the main system."""

    async def stream(self) -> AsyncGenerator[bytes, None]:
        """Stream audio data to Gemini Live."""
        while not self.quit.is_set():
            try:
                audio = await asyncio.wait_for(self.input_queue.get(), 0.1)
                yield audio
            except (asyncio.TimeoutError, TimeoutError):
                pass

    async def receive(self, frame: tuple[int, np.ndarray]) -> None:
        """Receive audio frame from user."""
        _, array = frame
        array = array.squeeze()
        audio_message = encode_audio(array)
        self.input_queue.put_nowait(audio_message)

    async def emit(self) -> tuple[int, np.ndarray] | None:
        """Emit audio response to user."""
        return await wait_for_item(self.output_queue)

    async def _check_microphone_availability(self):
        """Check if microphone is available and accessible."""
        print("ğŸ¤ [DEBUG] Checking microphone availability...")
        
        # This is a diagnostic check - actual microphone access happens in browser
        # We can't directly test getUserMedia from Python, but we can check system audio
        try:
            import platform
            system = platform.system()
            
            print(f"ğŸ’» [DEBUG] System: {system}")
            
            if system == "Linux":
                # Try to check if ALSA/PulseAudio is available
                try:
                    import subprocess
                    result = subprocess.run(["arecord", "-l"], capture_output=True, text=True, timeout=5)
                    if result.returncode == 0 and "card" in result.stdout.lower():
                        print("âœ… [DEBUG] Linux audio devices detected")
                        self.startup_diagnostics["microphone_test_passed"] = True
                    else:
                        print("âš ï¸ [DEBUG] No Linux audio devices found")
                except (subprocess.TimeoutExpired, FileNotFoundError):
                    print("âš ï¸ [DEBUG] Could not check Linux audio (arecord not available)")
            
            elif system == "Darwin":  # macOS
                print("ğŸ [DEBUG] macOS detected - check System Preferences for microphone access")
                self.startup_diagnostics["microphone_test_passed"] = True
            
            elif system == "Windows":
                print("ğŸª [DEBUG] Windows detected - check Windows Sound settings")
                self.startup_diagnostics["microphone_test_passed"] = True
            
            else:
                print(f"â“ [DEBUG] Unknown system: {system}")
                
        except Exception as e:
            print(f"âš ï¸ [DEBUG] Microphone check failed: {e}")
            # Don't fail startup for this
            pass
    
    def get_diagnostics(self) -> dict:
        """Get diagnostic information for troubleshooting."""
        return {
            "startup_diagnostics": getattr(self, "startup_diagnostics", {}),
            "active_tasks": len(self.processing_tasks),
            "session_active": self.session is not None,
            "quit_requested": self.quit.is_set()
        }
    
    def shutdown(self) -> None:
        """Shutdown handler."""
        print("ğŸ”„ [DEBUG] Shutting down bridge chat handler...")
        self.quit.set()


# Factory function to create the complete bridge chat system
def create_bridge_chat_stream(server_port: int = 7860, share: bool = False):
    """
    Create bridge design chat stream with Gemini Live API and supervisor tools.
    
    This replaces the mixed VoiceBridgeDesignAgent with clean separation:
    - Chat: Gemini Live API handles voice and conversation
    - Supervisor: Bridge design coordination via tools
    """
    if not CHAT_DEPENDENCIES_AVAILABLE:
        raise ImportError(
            "Chat dependencies not available. Install with:\n"
            "  uv add google-genai fastrtc"
        )
    
    import gradio as gr
    
    # Enhanced UI with better error handling and troubleshooting info
    stream = Stream(
        modality="audio",
        mode="send-receive",
        handler=BridgeChatHandler(),
        concurrency_limit=5,
        time_limit=300,  # 5 minutes session limit
        ui_args={
            "pulse_color": "rgb(0, 123, 255)",  # Bridge blue
            "icon_button_color": "rgb(0, 123, 255)",
            "title": "ğŸŒ‰ Bridge Design Chat Assistant",
            "description": """Voice chat for bridge design with specialized supervisor coordination.
            
**ğŸ¤ MICROPHONE TROUBLESHOOTING:**
â€¢ If "Record" button doesn't work: Check browser permissions (click microphone icon in address bar)
â€¢ If connection times out: Allow microphone access when browser asks
â€¢ If no permission popup: Try different browser (Chrome/Firefox) or refresh page
â€¢ Still having issues? Use text interface: `python -m bridge_design_system.agents.chat_voice text`

**âœ… QUICK FIX:** Clear browser data and refresh page, then click "Allow" when prompted""",
        },
        additional_inputs=[
            gr.Dropdown(
                label="Voice",
                choices=["Puck", "Charon", "Kore", "Fenrir", "Aoede"],
                value="Puck",
                info="Select Gemini voice for responses"
            ),
        ],
    )
    
    logger.info(f"âœ… Bridge chat stream ready on port {server_port}")
    return stream


def launch_bridge_chat_agent(server_port: int = 7860, share: bool = False, debug: bool = True):
    """Launch bridge design chat agent with voice interface."""
    
    if not CHAT_DEPENDENCIES_AVAILABLE:
        print("âŒ Chat dependencies not available.")
        print("Install with:")
        print("  uv add google-genai fastrtc")
        return
    
    print("ğŸŒ‰ Starting Bridge Design Chat Agent (Chat-Supervisor Pattern)")
    print("=" * 60)
    print("ğŸ’¬ Chat Layer: Gemini Live API")  
    print("ğŸ”§ Supervisor Layer: Bridge Design Coordination")
    print("ğŸ¤ Voice Interface: Real-time conversation")
    print("ğŸ› ï¸ Tools: Bridge design supervisor callable via voice")
    print(f"ğŸŒ Web Interface: http://127.0.0.1:{server_port}")
    print()
    print("ğŸ¤ [MICROPHONE SETUP] Common issues and solutions:")
    print("   âœ… When you click 'Record', browser will ask for microphone permission")
    print("   âœ… Click 'Allow' - don't click 'Block' or 'Don't Allow'")
    print("   âœ… If you accidentally blocked: click microphone icon in browser address bar")
    print("   âœ… If still stuck: try different browser or clear browser data")
    print("   âœ… Fallback option: use text interface instead")
    print()
    print("ğŸ› [DEBUG MODE] Console debugging enabled:")
    print("   - Function calls will be logged with ğŸš¨ markers")
    print("   - Triage agent interactions will be logged with ğŸ¯ markers")
    print("   - Errors will be logged with ğŸ’¥ markers")
    print("   - Tool calls will be logged with ğŸ”¥ markers")
    print()
    
    # Check API key
    if not os.getenv("GEMINI_API_KEY"):
        print("âŒ Error: GEMINI_API_KEY not found in environment variables")
        print("Please set your API key in your .env file:")
        print("  echo 'GEMINI_API_KEY=your_api_key_here' >> .env")
        print("Then restart the application.")
        return
    
    print("âœ… [DEBUG] GEMINI_API_KEY found in environment")
    
    try:
        print("ğŸš€ [DEBUG] Creating bridge chat stream...")
        # Create and launch
        chat_stream = create_bridge_chat_stream(server_port, share)
        print("ğŸŒ [DEBUG] Launching web interface...")
        print(f"ğŸ“± [DEBUG] Open your browser to: http://127.0.0.1:{server_port}")
        print("ğŸ¤ [DEBUG] Click the microphone button and speak to test the system")
        print()
        print("âš ï¸ [IMPORTANT] If microphone doesn't work:")
        print("   1. Check browser console (F12) for permission errors")
        print("   2. Clear browser data and refresh page")
        print("   3. Try different browser (Chrome, Firefox, Edge)")
        print("   4. Use text fallback: python -m bridge_design_system.agents.chat_voice text")
        print()
        print("ğŸ’¡ [USAGE TIP] Try saying:")
        print("   'What is the current bridge design status?'")
        print("   'Create a simple beam bridge'")
        print("   'Show me available tools'")
        print()
        
        # Enhanced launch with better error handling
        chat_stream.ui.launch(
            server_port=server_port, 
            share=share, 
            debug=debug,
            show_error=True,  # Show detailed error messages
            quiet=False,  # Don't suppress startup messages
            enable_queue=True,  # Enable request queue for better handling
        )
        
    except Exception as e:
        logger.error(f"Failed to launch chat agent: {e}")
        print(f"âŒ Launch failed: {e}")
        print("\nğŸ”§ Troubleshooting steps:")
        print("1. Check API key: export GEMINI_API_KEY=your_key")
        print("2. Install dependencies: uv add google-genai fastrtc")
        print("3. Check network connectivity")
        print("4. Try text interface: python -m bridge_design_system.agents.chat_voice text")
        print("5. Check port availability: netstat -tulpn | grep 7860")
        print("6. Try different port: python -m bridge_design_system.agents.chat_voice voice --port 7861")
        print("\nğŸ’¡ Most common issue: Browser microphone permissions")
        print("   Solution: Clear browser data, refresh page, click 'Allow' when prompted")


# Alternative text-based chat interface for testing
class BridgeTextChatInterface:
    """
    Text-based interface for bridge design chat (for testing without voice).
    
    Uses IPC to communicate with main.py system via text input/output.
    """
    
    def __init__(self):
        """Initialize text chat interface."""
        logger.info("ğŸŒ‰ Bridge text chat interface initialized for two-terminal architecture")
    
    def chat_loop(self):
        """Run interactive text chat loop."""
        print("ğŸŒ‰ Bridge Design Text Chat Interface (Two-Terminal Architecture)")
        print("=" * 70)
        print("Available commands:")
        print("  <any request>    - Send request to main.py via IPC")
        print("  status           - Check interface status")
        print("  reset            - Use 'reset' in main.py terminal")
        print("  help             - Show this help")
        print("  exit             - Exit chat")
        print("ğŸ’¡ Make sure main.py is running with --enable-command-server")
        print()
        
        while True:
            try:
                user_input = input("ğŸŒ‰ Bridge Chat> ").strip()
                
                if user_input.lower() == "exit":
                    print("ğŸ‘‹ Goodbye!")
                    break
                elif user_input.lower() == "help":
                    self._show_help()
                elif user_input.lower() == "status":
                    print("ğŸ“Š Status: Text chat interface using two-terminal IPC architecture")
                    print("   Main.py system should be running with --enable-command-server")
                elif user_input.lower() == "reset":
                    print("ğŸ”„ Reset: Use 'reset' command in main.py terminal")
                elif user_input:
                    # Send any non-empty request to main.py via IPC
                    print("\n" + "="*60)
                    print("ğŸ¯ [TEXT CHAT] Sending to main.py via IPC...")
                    print(f"ğŸ“ [USER INPUT] {user_input}")
                    print("="*60)
                    
                    try:
                        print("ğŸ”§ [DEBUG] Calling main.py via TCP IPC...")
                        response = asyncio.run(send_bridge_design_request(user_input))
                        
                        print(f"ğŸ“Š [DEBUG] Response received:")
                        print(f"    Success: {response.success}")
                        print(f"    Message length: {len(response.message) if response.message else 0} characters")
                        
                        if response.success:
                            print("âœ… [SUCCESS] Main.py processing completed successfully")
                            print(f"ğŸ“¤ [RESPONSE] {response.message}")
                        else:
                            print("âŒ [FAILURE] Main.py processing failed")
                            print(f"ğŸ’¥ [ERROR] {response.message}")
                            
                    except Exception as e:
                        print(f"ğŸ’¥ [EXCEPTION] Error in text chat: {e}")
                        print("ğŸ’¡ Make sure main.py is running with --enable-command-server")
                        import traceback
                        traceback.print_exc()
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ Goodbye!")
                break
            except Exception as e:
                print(f"âŒ Error: {e}")
    
    def _show_help(self):
        """Show help information."""
        print("ğŸŒ‰ Bridge Design Chat Commands (Two-Terminal Architecture):")
        print("  <any request>    - Send any request to main.py via IPC")
        print("                     Examples:")
        print("                     'Create a cable stayed bridge'")
        print("                     'Modify element 021 center point'")
        print("                     'What is the current design status?'")
        print("  status           - Check text chat interface status")
        print("  reset            - Use 'reset' command in main.py terminal")
        print("  help             - Show this help message")
        print("  exit             - Exit the chat interface")
        print()
        print("ğŸ’¡ All requests are sent via TCP to main.py which runs")
        print("   the bridge design system with triage agent coordination.")
        print("ğŸ’¡ Make sure main.py is running with --enable-command-server")


def launch_text_chat():
    """Launch text-based bridge design chat for testing."""
    try:
        chat = BridgeTextChatInterface()
        chat.chat_loop()
    except Exception as e:
        logger.error(f"Text chat failed: {e}")
        print(f"âŒ Text chat error: {e}")


def verify_system_setup():
    """Verify system setup and provide helpful diagnostics."""
    print("ğŸ” System Setup Verification")
    print("=" * 40)
    
    # Check dependencies
    print("ğŸ“¦ Checking dependencies...")
    if CHAT_DEPENDENCIES_AVAILABLE:
        print("  âœ… FastRTC and Google GenAI available")
    else:
        print("  âŒ FastRTC/Google GenAI missing")
        print("     Install with: uv add google-genai fastrtc")
        return False
    
    # Check API key
    print("ğŸ”‘ Checking API key...")
    if os.getenv("GEMINI_API_KEY"):
        print("  âœ… GEMINI_API_KEY found")
    else:
        print("  âŒ GEMINI_API_KEY missing")
        print("     Set in .env file: GEMINI_API_KEY=your_key_here")
        return False
    
    # Check system audio
    print("ğŸ¤ Checking system audio...")
    try:
        import platform
        system = platform.system()
        print(f"  â„¹ï¸ System: {system}")
        
        if system == "Linux":
            import subprocess
            try:
                result = subprocess.run(["arecord", "-l"], capture_output=True, text=True, timeout=3)
                if result.returncode == 0:
                    print("  âœ… Linux audio devices detected")
                else:
                    print("  âš ï¸ No Linux audio devices found")
            except (subprocess.TimeoutExpired, FileNotFoundError):
                print("  âš ï¸ Could not verify Linux audio (arecord not found)")
        else:
            print("  â„¹ï¸ System audio check skipped (not Linux)")
            
    except Exception as e:
        print(f"  âš ï¸ System audio check failed: {e}")
    
    # Check network
    print("ğŸŒ Checking network...")
    try:
        import socket
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(1)
        result = sock.connect_ex(('127.0.0.1', 7860))
        sock.close()
        if result == 0:
            print("  âš ï¸ Port 7860 already in use")
        else:
            print("  âœ… Port 7860 available")
    except Exception as e:
        print(f"  âš ï¸ Network check failed: {e}")
    
    print()
    print("ğŸ’¡ Common issues:")
    print("  â€¢ Microphone not working: Browser permissions (most common)")
    print("  â€¢ Connection timeout: Clear browser data, refresh page")
    print("  â€¢ No audio devices: Check system sound settings")
    print("  â€¢ Port in use: Stop other applications or use different port")
    print()
    return True

# CLI entry point
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "voice":
            if verify_system_setup():
                launch_bridge_chat_agent(debug=True)
        elif sys.argv[1] == "text":
            launch_text_chat()
        elif sys.argv[1] == "verify":
            verify_system_setup()
        else:
            print("Usage: python -m bridge_design_system.agents.chat_voice [voice|text|verify]")
    else:
        print("ğŸŒ‰ Bridge Design Chat Agent")
        print("Usage:")
        print("  python -m bridge_design_system.agents.chat_voice voice   # Voice interface")
        print("  python -m bridge_design_system.agents.chat_voice text    # Text interface")
        print("  python -m bridge_design_system.agents.chat_voice verify  # System check")
        print()
        print("ğŸ”§ Troubleshooting:")
        print("  â€¢ Run 'verify' first to check system setup")
        print("  â€¢ Most issues are browser microphone permissions")
        print("  â€¢ Use 'text' interface as fallback")
        print()
        print("Dependencies:")
        print("  uv add google-genai fastrtc") 